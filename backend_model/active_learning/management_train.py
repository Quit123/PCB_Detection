import os
import shutil
from pathlib import Path
from datetime import datetime
from ultralytics.models.yolo.detect import DetectionTrainer
from ..pre import split_dataset, batch_convert
import requests
import zipfile
from dotenv import load_dotenv

os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'

annotation_type = 'xml'

BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))  # é¡¹ç›®æ ¹ç›®å½•

train_path = os.path.join(BASE_DIR, "datasets/next_train/train/images").replace("\\", "/")
val_path = os.path.join(BASE_DIR, "datasets/next_train/val/images").replace("\\", "/")
yaml_content = f"""
train: {train_path}
val: {val_path}
nc: 6
names: ['Missing_hole', 'Mouse_bite', 'Open_circuit', 'Short', 'Spur', 'Spurious_copper']
"""

load_dotenv()  # é»˜è®¤ä» .env è¯»å–
SERVER_IP_DETECT = os.getenv("VITE_SERVER_IP_DETECT", "127.0.0.1")
SERVER_PORT_DETECT = os.getenv("VITE_SERVER_PORT_DETECT", "8000")


def find_latest_model_dir(base_dir, prefix='model_'):
    # è·å–æ‰€æœ‰ä»¥ prefix å¼€å¤´çš„æ–‡ä»¶å¤¹
    candidates = [
        d for d in os.listdir(base_dir)
        if os.path.isdir(os.path.join(base_dir, d)) and d.startswith(prefix)
    ]

    if not candidates:
        raise ValueError(f"No model directories found in {base_dir}")

    # æå–æ—¶é—´æˆ³å¹¶æ’åº
    def extract_timestamp(name):
        parts = name.split('_')
        # æœ€åä¸€ä¸ªéƒ¨åˆ†å’Œå€’æ•°ç¬¬äºŒä¸ªç»„æˆæ—¶é—´æˆ³ (YYYYMMDD_HHMMSS)
        timestamp = '_'.join(parts[-2:])
        return timestamp

    candidates.sort(key=lambda x: extract_timestamp(x), reverse=True)

    latest_dir = candidates[0]
    return os.path.join(base_dir, latest_dir, 'weights', 'best.pt')


def train(
        hsv_h_values=0.015,
        hsv_s_values=0.5,
        hsv_v_values=0.4,
        degrees_values=15,
        translate_values=0.1,
        scale_values=0.5,
        shear_values=2.5,
        perspective_values=0.001,
        mosaic_values=True
):
    base_dir = os.path.join(BASE_DIR, "runs", "active_learning")
    with open(os.path.join(BASE_DIR, "active_learning", "next_train.yaml"), "w") as f:
        f.write(yaml_content)
    data_url = os.path.join(BASE_DIR, "active_learning", "next_train.yaml")
    latest_model = find_latest_model_dir(base_dir)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    args = dict(
        model=latest_model,
        data=data_url,
        epochs=5,
        batch=2,
        project=base_dir,
        name=f"model_{hsv_h_values}_{hsv_s_values}_{hsv_v_values}_{degrees_values}_{translate_values}_{scale_values}_{shear_values}_{perspective_values}_{mosaic_values}_{timestamp}",
        hsv_h=hsv_h_values,
        hsv_s=hsv_s_values,
        hsv_v=hsv_v_values,
        degrees=degrees_values,
        translate=translate_values,
        scale=scale_values,
        shear=shear_values,
        perspective=perspective_values,
        mosaic=mosaic_values,
    )


    """
    | å‚æ•°           |æ”¹è¿›å»ºè®®                                                          | å¤‡æ³¨                         |
    | ------------- | -------------------------------------------------------------   | -------------------------- |
    | `hsv_h`       |å¯å°è¯• 0.05 \~ 0.1                                               | å¤ªå°å¯èƒ½å¢å¼ºæ•ˆæœä¸æ˜æ˜¾ï¼Œå¯¹é¢œè‰²é²æ£’æ€§ä¸è¶³       |
    | `hsv_s`       |å¯å°è¯• 0.5 \~ 0.9                                                | å¦‚æœé¢œè‰²å˜åŒ–å¯¹ç±»åˆ«åŒºåˆ†å½±å“å°ï¼Œå¯ä»¥é€‚å½“æ”¾å¤§      |
    | `hsv_v`       |å¯å°è¯• 0.2 \~ 0.6                                                | å¯å¢å¼ºäº®åº¦å˜åŒ–çš„é²æ£’æ€§                |
    | `degrees`     |å¯å°è¯• 5 \~ 20                                                   | æ ¹æ®å®é™…ç¼ºé™·è§’åº¦åˆ†å¸ƒè°ƒæ•´               |
    | `translate`   |å¯å°è¯• 0.05 \~ 0.2                                               | ç¼ºé™·ä½ç½®åˆ†å¸ƒè¾ƒé›†ä¸­æ—¶ï¼Œå¯å‡å°ï¼›åˆ†æ•£æ—¶å¯å¢å¤§      |
    | `scale`       |å»ºè®® 0.5 æ”¹ä¸º 0.5 Â± deltaï¼Œä¾‹å¦‚è®¾ç½® scale=0.5, scale\_range=(0.5, 1.5) | è¿‡å¤§æˆ–è¿‡å° scale å¯èƒ½å¯¼è‡´ç‰¹å¾ä¸¢å¤±æˆ–å½¢å˜ä¸åˆç† |
    | `shear`       |å¯å°è¯• 0 \~ 5                                                    | ä¸€èˆ¬å¯¹PCBç±»æ•°æ®ä½œç”¨è¾ƒå°              |
    | `perspective` |ä¿æŒå°å€¼å³å¯                                                        | å¤ªå¤§ä¼šå¼•å…¥ä¸è‡ªç„¶å½¢å˜                 |
    | `mosaic`      |å¯ä»¥è¯•è¯•å…³é—­åçœ‹å•æ ·æœ¬è®­ç»ƒæ•ˆæœï¼Œç‰¹åˆ«æ˜¯ç¼ºé™·å°ç›®æ ‡å¤šæ—¶                        |                            |
    """

    split_dataset(
        target_data_set='next_train',
        annotation_name='labels',
        image_name='images',
        train_ratio=0.8,
        next_train=True
    )

    trainer = DetectionTrainer(overrides=args)
    trainer.train()

    output_dir = os.path.join(base_dir, args["name"])
    zip_path = output_dir + ".zip"
    zip_directory(output_dir, zip_path)
    upload_zip_to_server(zip_path, f"http://{SERVER_IP_DETECT}:{SERVER_PORT_DETECT}/upload/")

    notify_training_complete()


def zip_directory(source_dir: str, output_zip_path: str):
    with zipfile.ZipFile(output_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for root, _, files in os.walk(source_dir):
            for file in files:
                file_path = os.path.join(root, file)
                arcname = os.path.relpath(file_path, source_dir)
                zipf.write(file_path, arcname)
    print(f"âœ… æ¨¡å‹ç›®å½•å·²æ‰“åŒ…ï¼š{output_zip_path}")


def upload_zip_to_server(zip_path: str, target_url: str):
    with open(zip_path, 'rb') as f:
        files = {'file': f}
        response = requests.post(target_url, files=files)
        print("ğŸ“¦ ä¸Šä¼ ç»“æœï¼š", response.status_code, response.text)
        response.raise_for_status()


def notify_training_complete():
    try:
        requests.post(f"http://127.0.0.1:8000/api/training-finished")
        print("âœ… å·²é€šçŸ¥è®­ç»ƒå®Œæˆ")
    except Exception as e:
        print("âŒ é€šçŸ¥å¤±è´¥ï¼š", e)

    # åŸ train å‡½æ•°æœ«å°¾æ·»åŠ ä»¥ä¸‹å†…å®¹
    # å‡è®¾è®­ç»ƒè¾“å‡ºç›®å½•å¦‚ä¸‹ï¼š
    # output_dir = os.path.join(BASE_DIR, args["name"])
    # zip_path = output_dir + ".zip"
    # zip_directory(output_dir, zip_path)
    #
    # # ä¸Šä¼ åˆ°å¦ä¸€ä¸ªåç«¯
    # try:
    #     upload_zip_to_server(zip_path, "http://192.168.1.100:8000/upload/")
    #     notify_training_complete()
    # except Exception as e:
    #     print("âŒ ä¸Šä¼ æˆ–é€šçŸ¥å¤±è´¥ï¼š", e)


if __name__ == '__main__':
    low_conf_dir = os.path.join(BASE_DIR, "active_learning", "low_conf_images")
    next_train_dir = os.path.join(BASE_DIR, "datasets", "raw", "next_train")
    history_dir = os.path.join(BASE_DIR, "datasets", "history")

    # low_conf_dir = BASE_DIR + './low_conf_images'
    # next_train_dir = '../datasets/raw/next_train'
    # history_dir = '../datasets/history'
    # move_labeled_data(low_conf_dir, next_train_dir, history_dir)
    print("æ•°æ®ç§»åŠ¨ä¸å†å²å¤‡ä»½å®Œæˆï¼")
    train()
    print("æ–°æ•°æ®å®Œæˆè®­ç»ƒï¼")
    notify_training_complete()
