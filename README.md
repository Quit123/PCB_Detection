# PCB Detection

> A hybrid active-learning based defect detection pipeline for industrial PCB AOI systems.  
> ğŸ¥‡ Winner of the **Shokz Global Excellence and Innovative Talent Summer School 2025 Gold Award**.

[ğŸ“½ï¸ Demo Video (MP4)](docs/demonstration.mp4)

## Environment Setup

This project is developed with **Python 3.10**. It is recommended to use **Conda** to create an isolated virtual environment.

### 1ï¸âƒ£ Create and Activate a Conda Environment

```bash
conda create -n yolov11 python=3.10
conda activate yolov11
```

### 2ï¸âƒ£ Install JupyterLab (Optional, for Interactive Development)

```bash
conda install jupyterlab
```

### 3ï¸âƒ£ Install PyTorch + CUDA 11.8

Please choose the appropriate CUDA version according to your GPU driver.
Example for **CUDA 11.8**:

```bash
pip install torch==2.0.0+cu118 torchvision==0.15.1+cu118 --extra-index-url https://download.pytorch.org/whl/cu118
```

### 4ï¸âƒ£ Install Project Dependencies

```bash
pip install requirements.txt
```
If any packages are missing, install them manually according to the error message: pip install <package_name>

---

## Dataset Directory Structure

The dataset is organized as follows, tailored for the **PCB defect detection** task:

```plaintext
./
â”œâ”€â”€ backend_detect/                    # Backend: Detection service module (e.g., active learning, inference service)
â”‚   â”œâ”€â”€ active_learning/               # Core logic for active learning
â”‚   â”œâ”€â”€ datasets/simulate_ready_push/  # Directory for simulated datasets
â”‚   â”œâ”€â”€ runs/active_learning/          # Logs and model checkpoints during active learning
â”‚   â”œâ”€â”€ server.py                      # Entry point for detection service
â”‚   â””â”€â”€ pre.py                         # Data preprocessing script

â”œâ”€â”€ backend_model/                     # Backend: Model training module (based on YOLO/Ultralytics)
â”‚   â”œâ”€â”€ active_learning/               # Shared active learning module with backend_detect
â”‚   â”œâ”€â”€ docker/                        # Docker deployment configurations
â”‚   â”œâ”€â”€ docs/                          # Project documentation directory
â”‚   â”œâ”€â”€ examples/                      # Example scripts and configuration files
â”‚   â”œâ”€â”€ runs/active_learning/          # Training and inference output results
â”‚   â”œâ”€â”€ tests/                         # Unit testing module
â”‚   â”œâ”€â”€ ultralytics/                   # YOLO source code and customized components
â”‚   â”œâ”€â”€ *.yaml                         # Dataset configuration files (e.g., BJ-PCB, GSD-PCB)
â”‚   â”œâ”€â”€ detect.py                      # Inference script
â”‚   â”œâ”€â”€ train.py / val.py / test.py    # Training, validation, and testing scripts
â”‚   â”œâ”€â”€ server.py                      # Entry point for training service
â”‚   â””â”€â”€ image_labeler.py               # Image labeling logic (for interactive annotation)

â”œâ”€â”€ frontend/                          # Frontend: Visualization interface built with Vue + TypeScript
â”‚   â”œâ”€â”€ public/                        # Static assets directory
â”‚   â”œâ”€â”€ src/                           # Frontend source code
â”‚   â”‚   â”œâ”€â”€ assets/                    # Image and media resources
â”‚   â”‚   â”œâ”€â”€ components/                # Core UI components (e.g., annotation area, results table)
â”‚   â”‚   â”‚   â”œâ”€â”€ ControlPanel.vue
â”‚   â”‚   â”‚   â”œâ”€â”€ DetectionArea.vue
â”‚   â”‚   â”‚   â”œâ”€â”€ LabelArea.vue
â”‚   â”‚   â”‚   â”œâ”€â”€ ResultTable.vue
â”‚   â”‚   â”‚   â””â”€â”€ TransfImg.vue
â”‚   â”‚   â”œâ”€â”€ stores/                    # State management modules (Pinia)
â”‚   â”‚   â”‚   â”œâ”€â”€ manageImg.ts
â”‚   â”‚   â”‚   â””â”€â”€ manageModel.ts
â”‚   â”‚   â””â”€â”€ main.ts / App.vue          # Project entry point
â”‚   â”œâ”€â”€ package.json                   # Frontend dependency management
â”‚   â””â”€â”€ vite.config.ts                 # Build configuration (Vite)

â”œâ”€â”€ requirements.txt                   # Python dependency list (backend environment)
â”œâ”€â”€ README.md                          # Project documentation
```

### Notes

* `Dataset_Name/images/` and `Dataset_Name/labels/` are used for **training, validation**, and **testing**.
* `raw/Dataset_Name/Annotations/` contains the **original annotation files** (e.g., XML) for each defect category.
* `raw/Dataset_Name/labels/` stores the **converted YOLO-format labels** used for training.
* It is recommended to organize the raw data into the YOLO-required structure `images/` and `labels/` during the preprocessing stage.

### Example Annotation File

YOLO-format label fileï¼ˆ`.txt`ï¼‰ï¼š

```
<class_id> <x_center> <y_center> <width> <height>
```

All values are **normalized to the range [0, 1]**.

For dataset splitting and format conversion, you may refer to the provided `pre.py` script or write your own batch processing tool.

---

### ğŸ§­ Usage Instructions

This project consists of **two backend modules** and **one frontend visualization interface**.
Follow the steps below to set up and run the system:

#### âœ… Install Dependencies

```bash
# Install backend dependencies
pip install -r requirements.txt

# Install frontend dependencies
cd frontend
npm install
```

#### ğŸš€ Launch Services

```bash
# Start Backend Service 1: Detection Service
cd backend_detect
python server.py

# Start Backend Service 2: Model Service
cd backend_model
python server.py

# Start Frontend Service (Vue + Vite)
cd frontend
npm run dev
```

#### âš™ï¸ Configure Service Endpoints (Optional)

The communication addresses among different modules are configured through `.env` files:

| è·¯å¾„                    | åŠŸèƒ½è¯´æ˜                                        |
| --------------------- | ------------------------------------------- |
| `backend_detect/.env` | Defines the IP and port for frontend access to `backend\_detect`             |
| `backend_model/.env`  | Defines the address for `backend\_model` to access `backend\_detect`    |
| `frontend/.env`       | Defines the addresses for the frontend to access both backends |

Example configuration for `frontend/.env`ï¼š

```env
VITE_DETECT_API_URL=http://localhost:8000
VITE_MODEL_API_URL=http://localhost:8001
```

Adjust the IP and port numbers according to your actual runtime environment to ensure smooth communication among services.

---

## âš ï¸ Notes

* If your GPU driver does not support CUDA 11.8, please visit the official PyTorch website
 to select a compatible version.
* The project supports Windows and Linux systems; Conda is recommended for Python environment management.
* If dependency conflicts or installation errors occur, try updating Conda first:

```bash
conda update -n base -c defaults conda
```


