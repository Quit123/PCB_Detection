import os
import shutil
from pathlib import Path
from datetime import datetime
import zipfile
import os
from ultralytics.models.yolo.detect import DetectionTrainer
from ..pre import split_dataset, batch_convert
import requests

os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'

annotation_type = 'xml'

BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))  # é¡¹ç›®æ ¹ç›®å½•

train_path = os.path.join(BASE_DIR, "datasets/next_train/train/images").replace("\\", "/")
val_path = os.path.join(BASE_DIR, "datasets/next_train/val/images").replace("\\", "/")
yaml_content = f"""
train: {train_path}
val: {val_path}
nc: 6
names: ['Missing_hole', 'Mouse_bite', 'Open_circuit', 'Short', 'Spur', 'Spurious_copper']
"""

def clear_directory(dir_path):
    """
    æ¸…ç©ºç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶å’Œå­æ–‡ä»¶å¤¹
    """
    dir_path = Path(dir_path)
    if dir_path.exists():
        for item in dir_path.iterdir():
            if item.is_file():
                item.unlink()
            elif item.is_dir():
                shutil.rmtree(item)


def move_labeled_data(low_conf_dir, next_train_dir, history_dir):
    labels_src = Path(low_conf_dir) / 'labels'
    images_src = Path(low_conf_dir) / 'raw'
    marked_images_src = Path(low_conf_dir) / 'marked'
    labels_dst = Path(next_train_dir) / 'labels'
    images_dst = Path(next_train_dir) / 'images'

    # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
    labels_dst.mkdir(parents=True, exist_ok=True)
    images_dst.mkdir(parents=True, exist_ok=True)

    print(f"æ¸…ç©º {labels_dst} ...")
    clear_directory(labels_dst)
    print(f"æ¸…ç©º {images_dst} ...")
    clear_directory(images_dst)
    clear_directory(marked_images_src)
    # print(f"æ¸…ç©º {images_dst} ...")

    # åˆ›å»ºå†å²ç›®å½•ï¼ˆæŒ‰æ—¥æœŸå‘½åï¼‰
    date_str = datetime.now().strftime('%Y%m%d_%H%M%S')
    history_subdir = Path(history_dir) / f'batch_{date_str}'
    history_labels = history_subdir / 'labels'
    history_images = history_subdir / 'images'
    history_labels.mkdir(parents=True, exist_ok=True)
    history_images.mkdir(parents=True, exist_ok=True)

    # ç§»åŠ¨å¹¶å¤‡ä»½æ ‡ç­¾æ–‡ä»¶
    label_files = list(labels_src.glob('*.txt'))
    for file in label_files:
        dst_path = labels_dst / file.name
        shutil.move(file, dst_path)
        # å¤åˆ¶åˆ°å†å²
        shutil.copy(dst_path, history_labels / file.name)
        print(f"å·²ç§»åŠ¨æ ‡ç­¾: {file} -> {dst_path}ï¼Œå¹¶å·²å¤‡ä»½åˆ°å†å²: {history_labels / file.name}")

    # ç§»åŠ¨å¹¶å¤‡ä»½å›¾ç‰‡æ–‡ä»¶
    image_files = list(images_src.glob('*.*'))  # å¯æŒ‡å®šæ ¼å¼å¦‚ '*.jpg'
    for file in image_files:
        dst_path = images_dst / file.name
        shutil.move(file, dst_path)
        # å¤åˆ¶åˆ°å†å²
        shutil.copy(dst_path, history_images / file.name)
        print(f"å·²ç§»åŠ¨å›¾ç‰‡: {file} -> {dst_path}ï¼Œå¹¶å·²å¤‡ä»½åˆ°å†å²: {history_images / file.name}")

# import os
from dotenv import load_dotenv
load_dotenv()  # é»˜è®¤ä» .env è¯»å–
SERVER_IP = os.getenv("VITE_SERVER_IP", "127.0.0.1")
SERVER_PORT = os.getenv("VITE_SERVER_PORT", "8000")

def upload_and_trigger_training(source_dir: str, output_zip_path: str):
    """
    å°† source_dir ç›®å½•ä¸‹æ‰€æœ‰å†…å®¹æ‰“åŒ…æˆ output_zip_path æ–‡ä»¶
    """

    source_dir = str(source_dir)
    output_zip_path = str(output_zip_path)

    if os.path.exists(output_zip_path):
        os.remove(output_zip_path)
        print(f"å·²åˆ é™¤å·²æœ‰ zip æ–‡ä»¶ï¼š{output_zip_path}")

    with zipfile.ZipFile(output_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for root, _, files in os.walk(source_dir):
            for file in files:
                file_path = os.path.join(root, file)
                arcname = os.path.relpath(file_path, source_dir)
                zipf.write(str(file_path), str(arcname))  # æ˜ç¡®è½¬ä¸º str
    print(f"å·²æ‰“åŒ…ä¸ºï¼š{output_zip_path}")
    with open(output_zip_path, 'rb') as f:
        files = {'file': f}
        response = requests.post(
            f"http://{SERVER_IP}:{SERVER_PORT}/upload/",
            files=files
        )
        print(response.json())
    # try:
    #     res_json = response.json()
    #     print("ğŸ“¦ ä¸Šä¼ ç»“æœï¼š", res_json)
    #     # ç¬¬äºŒæ­¥ï¼šå¦‚æœæˆåŠŸä¸Šä¼ å¹¶è§£å‹ï¼Œè§¦å‘è®­ç»ƒ
    #     if res_json.get("status") == "success":
    #         training_response = requests.post(f"http://{SERVER_IP_DETECT}:{SERVER_PORT_DETECT}/api/managing-training")
    #         print("ğŸš€ è§¦å‘è®­ç»ƒç»“æœï¼š", training_response.json())
    #     else:
    #         print("âŒ ä¸Šä¼ å¤±è´¥ï¼Œä¸è§¦å‘è®­ç»ƒ")
    # except Exception as e:
    #     print("âŒ è¯·æ±‚å¤±è´¥æˆ–å“åº”æ ¼å¼é”™è¯¯ï¼š", str(e))


if __name__ == '__main__':
    low_conf_dir = os.path.join(BASE_DIR, "active_learning", "low_conf_images")
    next_train_dir = os.path.join(BASE_DIR, "datasets", "raw", "next_train")
    history_dir = os.path.join(BASE_DIR, "datasets", "history")

    # low_conf_dir = BASE_DIR + './low_conf_images'
    # next_train_dir = '../datasets/raw/next_train'
    # history_dir = '../datasets/history'
    move_labeled_data(low_conf_dir, next_train_dir, history_dir)
    zip_output_path = os.path.join(BASE_DIR, "datasets", "next_train.zip")
    upload_and_trigger_training(next_train_dir, zip_output_path)
    print("æ•°æ®ç§»åŠ¨ä¸å†å²å¤‡ä»½å®Œæˆï¼")

